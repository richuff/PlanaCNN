{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-26T06:37:16.808312Z",
     "start_time": "2024-10-26T06:37:16.490710Z"
    }
   },
   "source": [
    "# tensorboard的使用\n",
    "# tensorboard --logdir=logs  在控制台输入打开tensorboard\n",
    "\n",
    "# 显示图像\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "writer = SummaryWriter(\"logs\")\n",
    "image_path = \"./train/ants_image/0013035.jpg\"\n",
    "\n",
    "img = Image.open(image_path)\n",
    "img_array = np.array(img)\n",
    "\n",
    "writer.add_image(\"test\",img_array,1,dataformats='HWC')"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T09:16:14.402613Z",
     "start_time": "2024-10-23T09:16:14.150809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# transforms的使用\n",
    "from PIL import Image\n",
    "from torchvision import  transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(\"logs\")\n",
    "\n",
    "img_path = \"D:\\\\MYproject\\\\djangoProject\\\\DjangoProject\\\\train\\\\ants_image\\\\5650366_e22b7e1065.jpg\"\n",
    "img = Image.open(img_path)\n",
    "tensor_trans = transforms.ToTensor()\n",
    "tensor_img = tensor_trans(img)\n",
    "writer.add_image(\"test\", tensor_img)\n",
    "\n",
    "#Normalize 归一化\n",
    "trans_norm = transforms.Normalize([1, 3, 5],[2,4,6])\n",
    "img_norm = trans_norm(tensor_img)\n",
    "writer.add_image(\"norm\", img_norm)\n",
    "\n",
    "writer.close()"
   ],
   "id": "1ad2986a0f19f168",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T06:37:26.347002Z",
     "start_time": "2024-10-26T06:37:26.312264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Normalize 归一化\n",
    "from torchvision import  transforms\n",
    "\n",
    "trans_norm = transforms.Normalize([1, 3, 5],[2,4,6])\n",
    "img_norm = trans_norm(tensor_img)\n",
    "writer.add_image(\"norm\", img_norm)"
   ],
   "id": "31f58fba72fdd73f",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transforms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#Normalize 归一化\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m trans_norm \u001B[38;5;241m=\u001B[39m \u001B[43mtransforms\u001B[49m\u001B[38;5;241m.\u001B[39mNormalize([\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m5\u001B[39m],[\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m4\u001B[39m,\u001B[38;5;241m6\u001B[39m])\n\u001B[0;32m      3\u001B[0m img_norm \u001B[38;5;241m=\u001B[39m trans_norm(tensor_img)\n\u001B[0;32m      4\u001B[0m writer\u001B[38;5;241m.\u001B[39madd_image(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnorm\u001B[39m\u001B[38;5;124m\"\u001B[39m, img_norm)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'transforms' is not defined"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T01:53:03.454714Z",
     "start_time": "2024-11-20T01:52:48.434404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Resize\n",
    "from torchvision import  transforms\n",
    "\n",
    "image_path = \"./train/ants_image/0013035.jpg\"\n",
    "img = Image.open(image_path)\n",
    "\n",
    "print(img.size)\n",
    "trans_resize = transforms.Resize((256, 256))\n",
    "# img PIL -->resize  img PIL\n",
    "img_resize = trans_resize(img)\n",
    "img_resize_tensor = tensor_trans(img_resize)\n",
    "writer.add_image(\"resize\", img_resize_tensor,0)\n",
    "print(img_resize_tensor)"
   ],
   "id": "d94b1ea30f660a34",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Resize\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchvision\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m  transforms\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mimg\u001B[49m\u001B[38;5;241m.\u001B[39msize)\n\u001B[0;32m      5\u001B[0m trans_resize \u001B[38;5;241m=\u001B[39m transforms\u001B[38;5;241m.\u001B[39mResize((\u001B[38;5;241m256\u001B[39m, \u001B[38;5;241m256\u001B[39m))\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# img PIL -->resize  img PIL\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'img' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-24T09:15:14.661863Z",
     "start_time": "2024-10-24T09:15:11.570386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# torchvision的datasets的使用\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "trans_totensor = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, transform=trans_totensor,download=True)\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, transform=trans_totensor,download=True)\n",
    "\n",
    "writer = SummaryWriter(\"p1\")\n",
    "for i in range(10):\n",
    "    img,target = train_set[i]\n",
    "    writer.add_image(\"test\",img,i)\n",
    "writer.close()"
   ],
   "id": "c29853b5bfe19d0c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T14:48:51.787269Z",
     "start_time": "2024-10-25T14:48:44.474843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# DataLoder\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=False, transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "test_loader = DataLoader(dataset=train_set,batch_size=64,shuffle=True,num_workers=0,drop_last=True)\n",
    "writer = SummaryWriter(\"p1\")\n",
    "\n",
    "step = 0\n",
    "for data in test_loader:\n",
    "    imgs ,targets = data\n",
    "    writer.add_images(\"test\",imgs,step)\n",
    "    step+=1\n",
    "writer.close()"
   ],
   "id": "11934e25051ca8d3",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T15:36:42.205750Z",
     "start_time": "2024-10-25T15:36:42.192695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 卷积神经网络\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "class MyMoudle(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = input+1\n",
    "        return output\n",
    "\n",
    "net = MyMoudle()\n",
    "x = torch.tensor(1.0)\n",
    "res = net.forward(x)\n",
    "print(res)        "
   ],
   "id": "db954044ad7e168",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T06:06:12.026157Z",
     "start_time": "2024-10-26T06:05:43.695253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 卷积层的使用\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=False, transform=torchvision.transforms.ToTensor())\n",
    "test_loader = DataLoader(dataset=train_set,batch_size=64,shuffle=True,num_workers=0,drop_last=True)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3,out_channels=6,kernel_size=3,stride=1,padding=0)\n",
    "    \n",
    "    def forward(self, input_value):\n",
    "        input_value = self.conv1(input_value)\n",
    "        return input_value\n",
    "    \n",
    "writer = SummaryWriter(\"p1\") \n",
    "net = Net()\n",
    "# Net(\n",
    "#   (conv1): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1))\n",
    "# )\n",
    "result_list = []\n",
    "step = 0\n",
    "for data in test_loader:\n",
    "    imgs,targets = data\n",
    "    output_value = net(imgs)\n",
    "    result_list.append(output_value)\n",
    "    writer.add_images(\"input\",imgs,step)\n",
    "    output_value = torch.reshape(output_value,(-1,3,30,30))\n",
    "    writer.add_images(\"output\",output_value,step)\n",
    "    step+=1\n",
    "print(len(result_list))\n",
    "writer.close()"
   ],
   "id": "f844a30d25e535de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T06:35:20.111438Z",
     "start_time": "2024-10-26T06:35:04.441154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 最大池化的使用\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=False, transform=torchvision.transforms.ToTensor())\n",
    "test_loader = DataLoader(dataset=train_set,batch_size=64,shuffle=True,num_workers=0,drop_last=True)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3,ceil_mode=False)\n",
    "    \n",
    "    def forward(self, input_value):\n",
    "        input_value = self.pool(input_value)\n",
    "        return input_value\n",
    "    \n",
    "writer = SummaryWriter(\"p1\") \n",
    "net = Net()\n",
    "result_list = []\n",
    "step = 0\n",
    "for data in test_loader:\n",
    "    imgs,targets = data\n",
    "    output_value = net(imgs)\n",
    "    result_list.append(output_value)\n",
    "    writer.add_images(\"input\",imgs,step)\n",
    "    writer.add_images(\"output\",output_value,step)\n",
    "    step+=1\n",
    "print(len(result_list))\n",
    "writer.close()"
   ],
   "id": "636e286ec9fd2e2f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T06:49:37.737448Z",
     "start_time": "2024-10-26T06:49:11.327434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 非线性激活Relu\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=False, transform=torchvision.transforms.ToTensor())\n",
    "test_loader = DataLoader(dataset=train_set,batch_size=64,shuffle=True,num_workers=0,drop_last=True)\n",
    "\n",
    "writer = SummaryWriter(\"p1\")\n",
    "input = torch.tensor([[1,-0.5],[-1,3]])\n",
    "input_reshape = torch.reshape(input,(-1,1,2,2))\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmod1 = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self,input):\n",
    "        output_value = self.sigmod1(input)\n",
    "        return output_value\n",
    "net = Net()\n",
    "step = 0\n",
    "for data in test_loader:\n",
    "    imgs,targets = data\n",
    "    output_value = net(imgs)\n",
    "    writer.add_images(\"input\",imgs,step)\n",
    "    writer.add_images(\"output\",output_value,step)\n",
    "    step+=1\n",
    "    \n",
    "writer.close()"
   ],
   "id": "be65045cb61b0675",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T05:02:53.120887Z",
     "start_time": "2024-10-27T05:02:47.219156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 线性层linear\n",
    "import torchvision\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=False, transform=torchvision.transforms.ToTensor())\n",
    "test_loader = DataLoader(dataset=train_set,batch_size=64,shuffle=True,num_workers=0,drop_last=True)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(196608,10)\n",
    "        \n",
    "        \n",
    "    def forward(self,input):\n",
    "        output_value = self.linear(input)\n",
    "        return output_value\n",
    "    \n",
    "net = Net()\n",
    "for data in test_loader:\n",
    "    imgs,targets = data\n",
    "    print(imgs.shape)\n",
    "    imgs = torch.flatten(imgs)\n",
    "    output_value = net(imgs)\n",
    "    print(output_value.shape)\n"
   ],
   "id": "ce0fb815593ee2f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T12:57:06.213577Z",
     "start_time": "2025-01-13T12:57:06.197570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(1, 10):\n",
    "    for j in range(1, i+1):\n",
    "        print(f\"{j}×{i}={i*j}\", end=\"\\t\")\n",
    "    print()"
   ],
   "id": "833595c81230bffc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1×1=1\t\n",
      "1×2=2\t2×2=4\t\n",
      "1×3=3\t2×3=6\t3×3=9\t\n",
      "1×4=4\t2×4=8\t3×4=12\t4×4=16\t\n",
      "1×5=5\t2×5=10\t3×5=15\t4×5=20\t5×5=25\t\n",
      "1×6=6\t2×6=12\t3×6=18\t4×6=24\t5×6=30\t6×6=36\t\n",
      "1×7=7\t2×7=14\t3×7=21\t4×7=28\t5×7=35\t6×7=42\t7×7=49\t\n",
      "1×8=8\t2×8=16\t3×8=24\t4×8=32\t5×8=40\t6×8=48\t7×8=56\t8×8=64\t\n",
      "1×9=9\t2×9=18\t3×9=27\t4×9=36\t5×9=45\t6×9=54\t7×9=63\t8×9=72\t9×9=81\t\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9ed6b18e9d0e066e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
